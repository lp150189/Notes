%%This is a very basic article template.
%%There is just one section and two subsections.
\documentclass{article}

\title{ CS-480\\ Midterm Review}
\begin{document}
\maketitle

\section{ Quality Insurance}

\subsection{Type of bugs}

-\textbf{Race conditions and deadlocks}: Racecondition is the beahvior
of an electronic of software system where output is dependent on the sequence or timing of other
uncontrollable events. \textbf{For example:} Multi threads application has many
threads that have the access to the same shared resource and can change these resource
at the same time which make the output becomes very unpredictable(bugs).\\
- \textbf{Deadblock}: is a situation in which two or more competing actions are
each waiting for the other to finish, and thus neither ever does. \textbf'{For
example:} Hold an Wait situation, a process ius currently holding at least one
resource and requesting additional resources which are being held by other
resources\\
- \textbf{Library Misuse}:\\
- \textbf{Logical error}:  a logic error is a bug in a program that causes
it to operate incorectly giving the wrong output, but not to terminate
abnormally(crash). To solve this bug, we should output all the variables to a
file or on the screen to define error in the code\\
- \textbf{Usability}: A usability bug is any unintended behavior by the product
noticed by and impacting the user. \textbf{For example:} the Wii remote control
detect the wrong motion from the users.\\
- \textbf{Performance Defects}:	The application doesn't have the performance
that qualifies the requirement. Performace defects involves things like
scalability, reliability and resource usage.\\
- \textbf{Error-handling error}:\\
- \textbf{Requirement bugs}: misunderstanding the requirement of the
application\\


\subsection{Terminology of bugs:}
- \textbf{Fault}: static problem in code, eg: unreachable code, in therac,
entered data is invalide, increment errorCounter instead of setting it to one
- \textbf{Error}: dynamic problem at runtime, eg: index out of bounds in array,
also therac 25, the errorCounter got overflows and goes to zero
- \textbf{Failure}: is the problem of the system. the machine. Eg: Server
got shutdown, or Ther25 believes it has valid data when it doesn't and shoot a
beam of radiation.
- \textbf{Hazard} is the resulting risk that actually happens. Eg: power grid
goes down, patient dies from radiation overdose
- \textbf{Faults in dead code}: those does not cause error
- \textbf{Multiple fauls:} may cause an error together
- \textbf{ Error:} Error does not always result in a failure to stop the system
like the example of server shutdown. Instead, the system or application might
still produce the output. Eg: Therac20- has the same faults, and the same error,
but there was a hardware override that prevented the failure

\subsection{The cost of defects}\
\begin{itemize} 
  \item 20\% of modules cause 80\% of defects. and 50\% are defect free
  \item \textbf{cost of repair} is potentially increase from 5x to 10x from the
  requirements to detection phase, somtimes evenmore
  \item \textbf{Rule of thumb}: 3x to 10x per phase in software lifecyle. 
\end{itemize}
 
\subsection{Kinds of Quality Assurance}
 - \textbf{Types:}
 \begin{itemize}
   \item Testing:
   \item Inspection:
   \item Program analysis
 \end{itemize}
 -\textbf{how to stop defect in the first place by Quality Assurance}
 \begin{itemize}
   \item getting the requirement right
   \item getting the design right
   \item implementing the design properly
 \end{itemize}
 - you would never never detect all defects, or prevent all defects\\
 - \textbf{V \& V}: stands for verification and validation
 \begin{itemize}
   \item verification is checking wherether the product matches its
   requirements
   \item validation is checking whether the product accomplish its goal
   \item testing is used to \textbf{verify} the program match the specified test
   \item \textbf{validate} is used to see if the specified tests are testing the
   right thing
 \end{itemize}
 
 \textbf{What kind of precisions of Quality Assurance}\begin{itemize}
   \item True positive: Quality Assurance detect these, and they exists
   \item True negative: Quality Assurance says no problem, and there is no
   problem
   \item False Positive: Quality Assurance detects problem, but there is no
   problem
   \item False Negative: Quality Assurance detecs no problems, but problems
   exists
 \end{itemize}
 -\textbf {Note:} False Positive, when Quality Assurance detect no problems, but
 there is problem takes a lot of time to investigate because too many of them
 relative to true positive. 
 
 \subsection{ How to evalutate Quality Assurance}
 \begin{itemize}
   \item \textbf{Overall} Cost: Cost of the techniques. Sunk Cost, and Recurring
   Cost
   \begin{itemize}
     \item \textbf{Sunkcost}: are cost of purchasing tools and setting them up.
     \item \textbf{Recurring Cost}: costs are the cost using the tool and
     maintaining any resources it needs.
   \end{itemize}
   \item \textbf{Bugs Found}: what classes of bugs are found? What is the
   relative importance of these classes of bugs. What are their relative
   expensive if the leak into the production code. eg; UI flaw will be very
   cheap comparing to security bugs( getting sued!)
   \item \textbf{Bug missed} What classes of bug this technique of Quality
   Assurance missed. What the cause or reason 
   \item \textbf{Techniqueover overlap} What other Quality Assurance techniques
   might find the similar type of bugs
   \item \textbf{ Cost of fix} what are the cost of fixing a bug once it is
   found with this technique. 3 things to consider
   \begin{itemize}
     \item cost to reproduce the bug for developer
     \item cost to find the root cause of the bug
     \item cost to fix the issue
   \end{itemize}
   \item \textbf{Stopping Point} determine when to stop using the technique
   \item \textbf{Intangible benefits}: Question for for this\ldots.
 \end{itemize}
 
 \subsection{Quality Assurance Plan}
  - A plan for doing QA helps us to decide what techniques to use, before it's
  too late. \\
  - \textbf{ Tetsting techniques}
  \begin{itemize}
    \item what will be testing
    \item how will testing take place
    \item when will testing take place, when it ends
    \item who will write the test, who will run them
    \item why do we believe the set of test is good
  \end{itemize}
  - In our plan, we should include the other techniques as well. For example;
  program analysis, or inspections. We should ask and answer the same question
  above for testing\\
  - One more important thing is provide the evidences why this set of QA
  techniques is good for your project\\
  -QA should be consious decision, not an accidential oversight
  
  
  % Section 2
  \section{Testing}
  \subsection{ Terminologies and Definitions}
  -\textbf{ Definition}: Direct execution of code on test data in a controlled
  environment\\
  - \textbf{Importance}: It only reveals the inconsistencies with
  specifications. It does not say the program is wrong or specification is
  wrong. \\
  - \textbf{goals of testing}:\\
  \begin{itemize}
    \item Reveal specific errors.
    \item Assess the overall quality.
    \item Verify the legal standards.
    \item Clarity the application specs and learn more about the program
  \end{itemize}
  - Categorize of testing
  \begin{itemize}
    \item Visibility
    \begin{itemize}
      \item Black Box: These test are made by looking at the specification,
      withou looking at the internal code
      \item White Box: These test are made by the knowledge of the code which
      are the internal control flow and structures
      \end{itemize}
    \item Automation:
    \begin{itemize} 
      \item Manual testing: keyboard pouding by human
      \item Automated testing: run by a machine
      \item Semi-automated testing:
      \end{itemize}
  \end{itemize}
  
  \subsection{ Unit Testing}
  - \textbf{Definition}the \" Unit\" implies the level that we are at. In the
  industry, unit testing is usually considered with method-level, but same principles can be
  applied at any level which are\\
  \begin{itemize}
    \item entire system
    \item subsystem
    \item single class
    \item single method
  \end{itemize}
  - \textbf{Properties:}Unit testing is: \\ 
  \begin{itemize}
    \item manually to create
    \item white box
    \item could be blackbox if devs test to an API
  \end{itemize}
  - \textbf{Test Scarffolding}: is a temporary sub-structure software that is
  used to test some input.\\
  \begin{itemize}
    \item provide a way to run the test
    \item JUnit is a test scaffold: 
    \item Driver: the component that calls the test
    \item Stubs: Component that the test calls and return canned data( the
    actual code that we wrote) \textbf{need more explanation}
    \item 3 phases of the test
    \begin{itemize}
      \item Setup phase: Create all input for the test, or any stubs
      \item Execute phase: Run the unit under test with the inputs
      \item Verification phase: Check output against exepcted outputs
    \end{itemize}
    \item Notes: 
    \begin{itemize}
      \item provide a different test for each different sets of input
      \item need to control the inputs, includes database things
      \item build stubs to handle these, stubs don't have to actually work, they
      are fake data
      \item verify all parts of the output.
      \item limit exercise phase to unit, so we can identify the
      faulty unit(\textbf{explanation})
      \end{itemize}
  \end{itemize}
  
  \subsection{Regression}
  \begin{itemize}
    \item the ability to re-ren your test at a later date
    \item it will prevent the old bug to recurring
    \item This is very low cost since you can store and run again at any moment
    \item Everytime you fix a bug, write the test for it, so you can run it in
    regression, so you don't re-create that bug again.
  \end{itemize}
  
  \subsection{Test-driven Development}
  - There are  3 ways you can develop the testing by this way
  \begin{itemize}
    \item Write your test first, then develop your code
    \begin{itemize}
      \item The tests your write must RUN and they should FAIL
      \item Ensure that it actually tests something
      \item Then write code to make it pass
     \end{itemize}
    \item Develop your code and then write your test very shortly after
    \begin{itemize}
      \item Upside: code is written first. Make stubbing easy because you know
      what the interface will be
      \item Downside: Code is written first. You tend to write code to pass it
      easily
    \end{itemize}
    \item Having a dedicated testee write the tests blackbox style
  \end{itemize}
  -There are major benefit to this development technique: you will be getting
  into a testing mindste and purposely trying to break your code
  
  \subsection{Coverage}
   \textbf{Definition:} is the proportion of code covered by your test
   -Kind of coverage
   \begin{itemize}
     \item line coverage
     \item branch coverage
     \item path coverage
   \end{itemize}
   - 100\% can be very difficult because there are a lot dead code, and code is
   not important for testing\\
   - However, coverage lets us see what code we have not yet written a test
   for\\
   \subsection{ Input selection}
   - Do a structual analysis of code and select inputs to exercise each branch
   or path through the code \\
   - Use equivalence classes. For example: list , list of 3 elements, list of 1
   elements, empty list , null list, list of list. \\
   - Randomly generate input. \\
   - Automatically generate inputs across space of inputs. \\
  
 \section{How to report bugs}
 \subsection{best practice for reporting bugs}
 \begin{itemize}
   \item Provide the reproducing steps
   \begin{itemize}
     \item provide detailed and simple steps how to reproduce the bugs
     \item helps with debugging
   \end{itemize}
   \item Be non-atagonistic
   \begin{itemize}
     \item Don't blame developers. everone write bugs
     \item Don't blame the testers. Testers frequently bring bad news.
   \end{itemize}
   \item Avoid using defects in performance evaluation( for example: give money
   to testers if they found find bugs, or punish the devs for bugs)
   \begin{itemize}
     \item Do that makde devs not take risks to add features
     \item Testers can create blakcmarket in bugs
     \item No one will try to find expensive bugs cuz there are eays one to find
   \end{itemize}
   \item identify the root cause
   \begin{itemize}
     \item how could this bug be prevented
     \item Could we discover it earlier
     \item any other related bugs. If yes, then fix them. Don't make tester find
     them all .
   \end{itemize}
 \end{itemize}
 
 \subsection{ Bug Report Outline}
 \begin{itemize}
   \item Repor step: detailed and simple
   \item Autal ouput comparison with the expected output
   \item Severity: how severe is the bug? does it crash the system or there is
   work around
   \item Priority: how important is the bug? Does it need to be fixed right away
   \item Status: what is the current status
   \begin{itemize}
     \item unconfirmed
     \item New/ confirmed
     \item assignend
     \item resolved
     \item reopened
     \item verified
     \item closed
    \end{itemize}
   \item Resolution:
   \begin{itemize}
     \item Fixed
     \item won't fix
     \item works for me
     \item duplicate
    \end{itemize}
 \end{itemize}
  
  
 \section{ Inspection}
 \subsection{Definition, Major benefits, inspection vs testing, formal vs
 informal Inspection}
 \begin{itemize}
   \item \textbf{Definition:} Inspections are reviews of software artifacts, the
   reviews can be formal process or an informal one
   \item The artifact could be code designs, or specification
   \item Code reviews are the most common form of inspections
   \item Majors benefits are:
   \begin{itemize}
     \item getting multiple perspectives on the artifacts
     \item sharing knowledge among team members
     \item finding defects earlier in the process
     \item Reducing rework and later effort
     \item Finding defects that are otherwise hard to detect through automated
     techniques
  \end{itemize}
  \item inpsection vs testing
  \begin{itemize}
    \item test a wider range of input
    \item generally better for \textbf{checking quality attributes ranther than
    functional defects}
    \item particularly gooat at \textbf{attributes such as maintainability,
    evolvability, and scalabality}
  \end{itemize}
  \item Formal vs informal inspection
  \begin{itemize}
    \item in both, we can use check list so that reviewers dont forget what to
    look for
    \item formal reviews takes place as part of meeting with several people
    \item informal reviews are usually online only and may invole only one or
    two reviewers
    \item While formal process can find more defects, it is definitely more
    expensive
  \end{itemize}
 \end{itemize}
 
 \subsection{Formal inspection}
 \begin{itemize}
   \item An example formal review process: Fagan-style inspection
   \item this techniqure require a group of 3 to 7 people
   \item Team size is larger for documents review and smaller for code review
   \item Team members have to read code in advance
   \item Expect people to be able to review 150 to 200 line of code per hour, or
   3 or 4 pages of code
   \item Team members have a meeting to discuss, and each member has a role 
   \begin{itemize}
     \item moderator organizes the process and keep everyone accountable. The
     moderator has to ensure the outcome of the meeting happens
     \item recoder record the log of what is discussed
     \item reader presents the material to the group, but this can't be the
     author
     \item the author can describe the intent of the code and reason for it, but
     otherwise keeps quiet during the meeting. Sometimes, authour might not
     attend at all
   \end{itemize}
   \item the metting itself should take no longer than 2 hours because the brain
   of human can only process many line of code in an amount of time
   \item after the meeting, th moderator folows up with the author to ensure all
   changes are mde
 \end{itemize}
 
 \subsection{inFormal inspection}
 \begin{itemize}
   \item The process start with the author sends a patch file to a reviewer:
   \begin{itemize}
     \item the patch file should be as small as possible, no more than 200 LOC
     \item Larger changes should be broken into multiple patches
   \end{itemize}
   \item the reviewers have to use an online tools to add comments
   \item the author makes suggested changes or responds to the comments
   \item when the reviewer is satisfied, the author is cleared to commit their
   code into the repository
 \end{itemize}
 
 
 
 \section{Reliability}
 \subsection{Definition}
 \begin{itemize}
   \item \textbf{ Definition}: Reliability is the realization that, despite your
   best efforts,error will happen. How do we prevent them from causing failures?
   \item We need to do an analysis of the inherent risks involved in the system
   \item These risks are inherent because they provide us with other benefits
   \item \textbf{inherent risk example}
   \begin{itemize}
     \item safety critical devices: Therac25, radiation can kill people, but we
     use the them to save live of cancer patients
     \item Interconected enterprises: example is the electric grid which are
     interconected to each other, we have to face cascade failures with these
     kind of inherent risk
     \item End-user interaction: Direct users interaction allow users to have
     more features and more flexibility. However, we have higher risk due to the
     uninformed individuals taking actions with high consequence. This could
     come from the UI defects or user error
     \item Electronic decision making system: we can save time by using
     electronic decision like in automobiles or trading. But the consequence
     happen much faster, perhaps even too fast to be able to mitigate them
  \end{itemize}
 \end{itemize}
 
 \subsection{Risk Mitigation}
 - If we cannot avoid risks entirely, we must consider how to mitigate them. We
 can either be preventative or reactive
 \begin{itemize}
   \item preventative
   \begin{itemize}
     \item Inspections can identify before they enter production
     \item Testing can be used to identify error
     \item Can also use other coding practices and measurements to prevent
     faults
   \end{itemize}
   \item reactive
   \begin{itemize}
     \item dynamically adjust when failures are detected in order to avoid
     hazards
     \item Fault tolerant system ( handle multiple errors ) prevents errors
     causing system wide failure
   \end{itemize}
   \item Risk management
   \begin{itemize}
     \item involves indentify the risks, tracking them, and mitigating them
     \item might have a risk manager incharge of this
     \item process might involve listing all the list or  listing the top ten
     bug along with the mitigation techniques
     \item might also perform a fualty tree for safety-critical  system.
   \end{itemize}
  
   \item Risk Coverage
   \begin{itemize}
     \item There is no way to completely cover risk
     \item There will be always be known risk( identified and hopefully be
     mitigated), and unknown risks( have not been identified)
     \item it is frequent better to at least find as many known risk as
     possible, even if not all of them can be mitigated
   \end{itemize}
 
 \end{itemize}
 
 \section{Program analysis}
 \subsection{Definition}
 - Program analysis  tools read or run code to automatically detect defects or
 provide further understanding about the code
 \begin{itemize}
   \item Static analysis is the form which read the code( static: doesn't move)
   \item Dynamic analysis is the form which runs the code
 \end{itemize}
 
 
 \section{ Static analysis}
 
 
 
\end{document}
